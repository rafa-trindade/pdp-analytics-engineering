# âš™ï¸ pdp-analytics-engineering

[![Projeto Badge](https://img.shields.io/badge/-pdp--hospedagem-2B5482?style=flat-square&logo=github&logoColor=fff)](https://github.com/rafa-trindade/pdp-hospedagem)

Este projeto tem como objetivo **implementar, modelar e consumir um Data Warehouse** a partir de dados transacionais do projeto **[pdp-hospedagem](https://github.com/rafa-trindade/pdp-hospedagem)**, utilizando uma arquitetura moderna de dados. Para isso, sÃ£o empregadas as ferramentas **Apache Airflow**, **DBT (Data Build Tool)** e **Power BI**, integradas em um fluxo de ponta a ponta.

O **Airflow** Ã© responsÃ¡vel pela orquestraÃ§Ã£o dos pipelines de extraÃ§Ã£o, carregamento e transformaÃ§Ã£o dos dados; o **DBT** atua na transformaÃ§Ã£o e modelagem dos dados dentro do Data Warehouse, aplicando boas prÃ¡ticas de engenharia analÃ­tica; e o **Power BI** Ã© utilizado na camada de visualizaÃ§Ã£o e anÃ¡lise, permitindo a criaÃ§Ã£o de dashboards interativos e indicadores de desempenho.

## ğŸ“„ RelatÃ³rio de ExecuÃ§Ã£o do Projeto:

- âœ… CriaÃ§Ã£o da dimensÃ£o `dim_data` via Python que serÃ¡ utilizada como **seeds** no DBT.  
- âœ… IngestÃ£o de dados transacionais fictÃ­cios no banco de dados **SQL Server** do projeto [**pdp-hospedagem**](https://github.com/rafa-trindade/pdp-hospedagem) utilizando [**datafaker-rafatrindade**](https://github.com/rafa-trindade/datafaker-rafatrindade).  
- âœ… **ConteinerizaÃ§Ã£o** do projeto utilizando **Docker**.
- âœ… ImplementaÃ§Ã£o da **extraÃ§Ã£o (Extract)** dos dados transacionais via pipeline orquestrada no **Airflow**, com arquivos extraÃ­dos salvos na pasta `data/extracted`.  
- âœ… ImplementaÃ§Ã£o da **Carga (Load)** dos dados extraÃ­dos do SQL Server para a camada **raw** do Data Warehouse (PostgreSQL) via pipeline orquestrada no **Airflow**.  
- âœ… **TransformaÃ§Ãµes (Transform)** e modelagem dos dados no DBT, estruturando as camadas **staging** e **core**.  
- âœ… ImplementaÃ§Ã£o de **testes automatizados** via DBT para garantir a **qualidade dos dados** na camada **core**.  
- âœ… Modelagem de tabelas analÃ­ticas a partir das **tabelas fato e dimensÃ£o** utilizando o DBT na camada **mart**.  
- âœ… **Dataviz:** Exemplo de consumo dos modelos analÃ­ticos no **Power BI** com criaÃ§Ã£o de dashboards e relaÃ³rios.  

![projeto-pdp-analytics-engineering](https://i.postimg.cc/8z3CYGt1/projeto-v8.png)

___

## ğŸ§  OrquestraÃ§Ã£o das DAGs no Airflow:

![dag](docs/dag.png)

- `extract_task`: Extrai os dados do **SQL Server**.  
- `load_task`: Carrega os dados brutos na camada **raw** **(PostgreSQL)**.  
- `dbt_staging_task`: Cria as views da camada **staging**, responsÃ¡veis por padronizar e preparar os dados brutos.  
- `dbt_seed_task`: Carrega as dimensÃµes estÃ¡ticas **(seeds)**.  
- `dbt_core_task`: Modela e cria as tabelas **fato** e **dimensÃ£o** materializadas na camada **core**.  
- `dbt_test_task`: Executa **testes automatizados** de qualidade de dados na camada **core**.  
- `dbt_marts_task`: Gera as views analÃ­ticas da camada **marts**, prontas para consumo no Power BI.

---

## ğŸ“Š Camada Marts - Data Warehouse:

A camada **Marts** contÃ©m views analÃ­ticas derivadas das tabelas da camada **Core**. Cada subpasta organiza os modelos por **categoria de anÃ¡lise** ou **tipo de mÃ©trica**, facilitando a consulta e o consumo dos dados.

## ğŸ¦ Financeiro:

## `dw_marts.financeiro_receita_mensal`
**DescriÃ§Ã£o:**  
Apresenta a receita total mensal proveniente de hospedagens e consumos, consolidando ambas as fontes.

**Tabelas utilizadas:** `fact_hospedagem` `fact_consumo` `dim_data`

| Campo | Tipo | DescriÃ§Ã£o |
|--------|-------|-----------|
| **data** | DATE | Data obtida via `dim_data` (campo `data`) |
| **origem** | TEXT | `'HOSPEDAGEM'` ou `'CONSUMO'` conforme a tabela fato de origem |
| **cmv** | BOOLEAN | `FALSE` para hospedagem, `TRUE` para consumo |
| **total_receita** | NUMERIC | Soma dos valores (`hospedagem_valor` ou `valor_consumacao`) agrupados por mÃªs/ano |

---

## `dw_marts.financeiro_despesa_mensal`
**DescriÃ§Ã£o:**  
Consolida as despesas mensais, agrupadas por tipo de despesa (campo `topo`).

**Tabelas utilizadas:** `dim_despesas`

| Campo | Tipo | DescriÃ§Ã£o |
|--------|-------|-----------|
| **data** | DATE | Data da despesa conforme registrada na dim_despesas |
| **tipo_despesa** | TEXT | Agrupamento pelo campo `tipo` da `dim_despesas` |
| **total_despesa** | NUMERIC | Soma dos valores (`valor`) para o mesmo tipo/mÃªs/ano |

---

## ğŸ¨ Hospedagem:

## `dw_marts.hospedagem_resumo`
**DescriÃ§Ã£o:**  
Resumo diÃ¡rio das receitas de hospedagens, com observaÃ§Ãµes sobre feriados e finais de semana.

**Tabelas utilizadas:** `fact_hospedagem` `dim_data`

**Campos resultantes:**

| Campo | Tipo | DescriÃ§Ã£o |
|--------|-------|-----------|
| **data** | DATE | Data da hospedagem |
| **hospedagem** | NUMERIC | Soma de `hospedagem_valor` por data |
| **consumo** | NUMERIC | Soma de `total_consumo` por data |
| **dia_semana** | TEXT | Nome do dia da semana correspondente Ã  data, vindo da `dim_data` |
| **observacao** | TEXT | Nome do feriado, `'FDS'` ou `'-'` validado na `dim_data`|
| **quantidade_hospedes** | INT | Soma de `hospedagem_qtd_pessoas` |
| **total** | NUMERIC | Soma de `hospedagem + consumo` |
| **apt** | NUMERIC(10,2) | Valor mÃ©dio de hospedagem por hÃ³spede |

---

## ğŸ“Š Consumo e ApresentaÃ§Ã£o - Power BI:

## `pdp_dw_powerbi.pbix`

 <!--![powerbi](https://i.postimg.cc/B6dHfys4/pdp-dw-powerbi.png) -->
![powerbi](https://i.postimg.cc/mDc7LbJq/pdp-dw-powerbi-v2.png)


---

## ğŸ§© Modelagem:

## `modelo_olap`
![Diagrama OLAP](https://i.postimg.cc/25bxpzYF/olap-model-v3.png)

## ğŸ’» Origem dos Dados Transacionais:

## `pdp-hospedagem` [[link]](https://github.com/rafa-trindade/pdp-hospedagem)
![Diagrama OLTP](https://i.postimg.cc/ZnRRgqtB/oltp-model-v4.png)

---

## âš¡ InicializaÃ§Ã£o do ambiente com Docker:

```bash
docker-compose build
docker-compose up -d
```

## âš¡ Exemplo de execuÃ§Ã£o manual para teste da DAG de extraÃ§Ã£o:

```bash
docker exec -it airflow airflow tasks test elt_dag extract_data 2025-10-24
```

## âš¡ Exemplo de execuÃ§Ã£o manual para teste da DAG de carga:

```bash
docker exec -it airflow airflow tasks test elt_dag load_data 2025-10-24
```

---

## ğŸ“¦ Bibliotecas Utilizadas:

**Ambiente:** Python 3.11 + Airflow 2.9.3

| Pacote            | VersÃ£o      | ObservaÃ§Ã£o |
|-------------------|------------|------------|
| **pandas**        | 2.3.3      | ManipulaÃ§Ã£o e transformaÃ§Ã£o de dados |
| **requests**      | 2.32.3     | RequisiÃ§Ãµes HTTP e integraÃ§Ã£o de APIs |
| **python-dotenv** | 1.0.1      | Carregamento de variÃ¡veis de ambiente do arquivo `.env` |
| **dbt-core**      | 1.10.13    | TransformaÃ§Ãµes e modelagem no Data Warehouse |
| **dbt-postgres**  | 1.9.1      | Adaptador DBT para PostgreSQL |
| **SQLAlchemy**    | 2.0.22     | ORM e conexÃ£o com bancos de dados |
| **psycopg2-binary** | 2.9.7   | Driver PostgreSQL para Python |
| **pyodbc**        | 5.3.0      | Driver ODBC para conexÃ£o com diversos bancos |
| **msodbcsql17** | Microsoft (APT) | Driver oficial ODBC do SQL Server para Linux |

---

## ğŸ—‚ï¸ Estrutura do Projeto:

```text
pdp-analytics-engineering/
â”œâ”€â”€ airflow/                 # OrquestraÃ§Ã£o de pipelines ETL/ELT com Airflow
â”‚   â”œâ”€â”€ dags/                # DefiniÃ§Ã£o dos DAGs
â”‚   â”œâ”€â”€ logs/                # Armazenamento de logs de execuÃ§Ã£o dos DAGs
â”‚   â””â”€â”€ plugins/             # Plugins customizados do Airflow
â”œâ”€â”€ config/                  # Arquivos de configuraÃ§Ã£o do projeto
â”œâ”€â”€ data/                    # Dados brutos
â”œâ”€â”€ dbt/                     # Projeto DBT
â”‚   â”œâ”€â”€ models/              
â”‚   â”‚   â”œâ”€â”€ staging/         # Modelos staging (limpeza e padronizaÃ§Ã£o de dados)
â”‚   â”‚   â”œâ”€â”€ core/            # Modelos core (dados integrados e limpos)
â”‚   â”‚   â””â”€â”€ marts/           # Modelos marts (tabelas para anÃ¡lise e dashboards)
â”‚   â”œâ”€â”€ seeds/               # Seeds (ex.: dim_date)
â”‚   â”œâ”€â”€ tests/               # Testes de qualidade do DBT
â”‚   â”œâ”€â”€ dbt_project.yml      # ConfiguraÃ§Ã£o do projeto DBT
â”‚   â””â”€â”€ profiles.yml         # ConfiguraÃ§Ã£o de conexÃ£o com o banco
â”œâ”€â”€ docs/                    # DocumentaÃ§Ã£o do projeto
â”‚   â”œâ”€â”€ diagrams/            # Diagramas de bancos OLTP e DWH
â”‚   â”œâ”€â”€ powerbi_screenshots/ # Capturas de tela de dashboards
â”‚   â””â”€â”€ data_dictionary.md   # DicionÃ¡rio de dados
â”œâ”€â”€ reports/                 # RelatÃ³rios Power BI exportados
â”œâ”€â”€ scripts/                 # Pipelines ETL e scripts auxiliares (ex.: geraÃ§Ã£o de seeds via Python)
â”œâ”€â”€ .env                     # VariÃ¡veis de ambiente do projeto
â”œâ”€â”€ docker-compose.yml       # ConfiguraÃ§Ã£o para execuÃ§Ã£o de containers Docker
â”œâ”€â”€ Dockerfile               # DefiniÃ§Ãµes da imagem Docker do projeto
â”œâ”€â”€ main.py                  # Script para execuÃ§Ã£o local
â”œâ”€â”€ README.md                # DocumentaÃ§Ã£o do projeto
â””â”€â”€ requirements.txt         # DependÃªncias Python
```

